{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BaTKLgE8FKSt",
    "outputId": "f5fff2db-0fba-49b4-ebd2-617a430cb934"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all nescessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-_htQga1wDu",
    "outputId": "e933b886-6282-4826-cdc8-5c4353dbb6dd"
   },
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqhYRRAI2LVa",
    "outputId": "88a9b9b2-6b67-4c6d-9264-5325e610df8a"
   },
   "outputs": [],
   "source": [
    "!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xo8c9fHOBSUv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N04_Nn8h2jrw",
    "outputId": "54c32f42-87c8-42ac-e0f6-27b8d6d8f751"
   },
   "outputs": [],
   "source": [
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define download from url function and download SAM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file(url, save_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        \n",
    "        with open(save_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully: {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "url = 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
    "\n",
    "save_path = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "\n",
    "download_file(url, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_U2Ze_LP2eoE",
    "outputId": "5f904001-1321-4d25-a5dd-a6ed72be5c5e"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_h_4b8939.pth\")\n",
    "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCQjouZs36GD"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_TYPE = \"vit_h\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the SAM model with the downloaded weight on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjRZacqh3_UX"
   },
   "outputs": [],
   "source": [
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XceNZgA587rG"
   },
   "outputs": [],
   "source": [
    "mask_predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the box for masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vFiAca29RIE"
   },
   "outputs": [],
   "source": [
    "default_box = {'x': 132, 'y': 151, 'width': 300, 'height': 300, 'label': ''}\n",
    "\n",
    "box = default_box\n",
    "box = np.array([\n",
    "    box['x'],\n",
    "    box['y'],\n",
    "    box['x'] + box['width'],\n",
    "    box['y'] + box['height']\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = os.path.join(HOME, 'Original/train/')\n",
    "os.makedirs(source_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the WBC in the middle of the image and download the segmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "jFBCjxQd5BL6",
    "outputId": "1bb01eb3-4e22-4499-b2da-a059c0156f9b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "source_dir = os.path.join(HOME, 'Original/train/')\n",
    "target_root_dir = os.path.join(HOME, 'Original_segmentation/train/')\n",
    "\n",
    "os.makedirs(target_root_dir, exist_ok=True)\n",
    "\n",
    "for folder_name in os.listdir(source_dir):\n",
    "    folder_path = os.path.join(source_dir, folder_name)\n",
    "\n",
    "    target_folder_path = os.path.join(target_root_dir, folder_name)\n",
    "    os.makedirs(target_folder_path, exist_ok=True)\n",
    "\n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        IMAGE_PATH = os.path.join(folder_path, image_filename)\n",
    "        image_bgr = cv2.imread(IMAGE_PATH)\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        mask_predictor.set_image(image_rgb)\n",
    "\n",
    "        masks, scores, logits = mask_predictor.predict(\n",
    "            box=box,\n",
    "            multimask_output=True\n",
    "        )\n",
    "\n",
    "        mask = masks[np.argmax(scores)]\n",
    "        mask = mask.astype(bool)\n",
    "        masked_image = np.zeros_like(image_rgb)\n",
    "\n",
    "        for c in range(3):\n",
    "            masked_image[:, :, c] = image_rgb[:, :, c] * mask\n",
    "\n",
    "        y_indices, x_indices = np.where(mask)\n",
    "        x_min, x_max = x_indices.min(), x_indices.max()\n",
    "        y_min, y_max = y_indices.min(), y_indices.max()\n",
    "\n",
    "        cropped_image = masked_image[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        cropped_image_path = os.path.join(target_folder_path, image_filename + \"_segment.png\")\n",
    "        cv2.imwrite(cropped_image_path, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
